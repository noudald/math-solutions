\section*{Chapter 7 - Operators on Inner Product Spaces}

For all exercises we assume that all vector spaces are finite dimensional.


\subsection*{Section 7A - Self-Adjoint and Normal Operators}

\subsubsection*{Exercise 1}

Suppose $n$ is a positive integer.
Define $T \in \mathcal{L}(\mathbb{F}^n)$ by $T(x_1, x_2, ..., x_n) = (0, x_1, ..., x_{n-1})$.
Find a formula for $T^*(x_1, x_2, ..., x_n)$.

\subsubsection*{Solution}

Take $T^*(y_1, y_2, ..., y_n) = (y_2, y_3, ..., y_n, 0)$, then
\begin{equation*}
    \begin{split}
        \langle T(x_1, x_2, ..., x_n), (y_1, y_2, ..., y_n) \rangle
            &= \langle (0, x_1, x_2, ..., x_{n-1}), (y_1, y_2, ..., y_n) \rangle \\
            &= x_1 y_2 + x_2 y_3 + ... + x_{n-1} y_n \\
            &= \langle (x_1, x_2, ..., x_n), (y_2, y_3, ..., y_{n-1}, 0) \rangle \\
            &= \langle (x_1, x_2, ..., x_n), T^*(y_1, y_2, ..., y_n) \rangle.
    \end{split}
\end{equation*}


\subsubsection*{Exercise 2}

Suppose $T \in \mathcal{L}(V, W)$.
Prove that the following are equivalent
\begin{enumerate}
\item $T = 0$,
\item $T^* = 0$,
\item $T^* T = 0$,
\item $T T^* = 0$.
\end{enumerate}

\subsubsection*{Solution}

Note that $\langle Tv, w\rangle = \langle v, T^*w \rangle$, for all $v, w$.
In particular $\langle Tv, Tv \rangle = \langle v, T^*Tv \rangle = \langle T^*T v, v \rangle$ and $\langle T^*w, T^*w\rangle = \langle T T^* w, w \rangle$ for all $v \in V$ and $w \in W$.
If $T = 0$, then $T^*T = 0$ and $TT^* = 0$.
Conversely if $T^*T = 0$ or $TT^* = 0$, then, using the first equation, $\langle Tv, Tv \rangle = 0$, hence $Tv = 0$ for all $v \in V$.
Therefore, $T = 0$.
If $T^* = 0$, then $T^*T = 0$ and $TT^* = 0$.
Conversely if $T^*T = 0$ or $TT^* = 0$, then, using the second equation, $\langle T^*v, T^*v \rangle = 0$, hence $T^*v = 0$ for all $v \in V$.
Therefore, $T^* = 0$.


\subsubsection*{Exercise 3}

Suppose $T \in \mathcal{L}(V)$ and $\lambda \in \mathbb{F}$.
Prove that $\lambda$ is an eigenvalue of $T$ if and only if $\overline{\lambda}$ is an eigenvalue of $T^*$.


\subsubsection*{Solution}

Note that from the previous exercise $T - \lambda I = 0$ if and only if $T^* - \overline{\lambda} I = (T - \lambda I)^* = 0$.
Which gives the result.


\subsubsection*{Exercise 4}

Suppose $T \in \mathcal{L}(V)$ and $U$ a subspace of $V$.
Show that $U$ is invariant under $T$ if and only if $U^{\perp}$ is invariant under $T^*$.

\subsubsection*{Solution}

\begin{itemize}
    \item[$\rightarrow)$] Let $v \in U^{\perp}$, so for all $u \in U$ we have $\langle u, v \rangle = 0$.
        We have, for all $v$, $\langle u, T^*v\rangle = \langle Tu, v\rangle = 0$, because $Tu \in U$, so $T^*u \in U^{\perp}$.
    \item[$\leftarrow)$] Let $u \in U$.
        For all $v \in U^{\perp}$, we have $\langle Tu, v \rangle = \langle u, T^*v \rangle = 0$, because $T^*v \in U^{\perp}$.
        Therefore $Tu \in (U^{\perp})^{\perp} = U$.
\end{itemize}


\subsubsection*{Exercise 5}

Suppose $T \in \mathcal{L}(V, W)$.
Suppose $e_1, e_2, ..., e_n$ is an orthonormal basis of $V$ and $f_1, f_2, ..., f_m$ is an orthonormal basis of $W$.
Prove that
\begin{equation*}
    ||Te_1||^2 + ... + ||Te_n||^2 = ||T^*f_1||^2 + ... + ||T^*f_m||^2.
\end{equation*}

\subsubsection*{Solution}

Because $\{e_i\}$ and $\{f_j\}$ are orthonormal basis we can write
\begin{equation*}
    Te_i = \langle Te_i, f_1 \rangle f_1 + ... + \langle Te_i, f_m \rangle f_m = \sum_{j=1}^m \langle Te_i, f_j \rangle f_j,
\end{equation*}
and
\begin{equation*}
    T^*f_j = \langle T^*f_j, e_1 \rangle e_1 + ... + \langle T^*f_j, e_n \rangle = \sum_{i=1}^n \langle T^*f_j, e_i \rangle e_i.
\end{equation*}
We have
\begin{equation*}
    \begin{split}
        ||Te_1||^2 + ... + ||Te_n||^2
            &= \sum_{i=1}^n \langle Te_i, Te_i \rangle \\
            &= \sum_{i=1}^n \langle \sum_{j=1}^m \langle Te_i, f_j \rangle f_j, Te_i \rangle \\
            &= \sum_{i=1}^n \sum_{j=1}^m \langle Te_i, f_j \rangle \langle f_j, Te_i \rangle \\
            &= \sum_{j=1}^m \sum_{i=1}^n \langle e_i, T^*f_j \rangle \langle T^*f_j, e_i \rangle \\
            &= \sum_{j=1}^m \sum_{i=1}^n \langle T^*f_j, e_i \rangle \langle e_i, T^*f_j \rangle \\
            &= \sum_{j=1}^m \langle \sum_{i=1}^n \langle T^*f_j, e_i \rangle e_i, T^*f_j \rangle \\
            &= \sum_{j=1}^m \langle T^*f_j, T^*f_j \rangle
            = ||T^*f_1||^2 + ... + ||T^*f_m||^2.
    \end{split}
\end{equation*}


\subsubsection*{Exercise 6}

Suppose $T \in \mathcal{L}(V, W)$.
Prove that
\begin{itemize}
\item[(a)] $T$ is injective if and only if $T^*$ is surjective.
\item[(b)] $T$ is surjective if and only if $T$ is injective.
\end{itemize}

\subsubsection*{Solution}

Follows from 7.6.
$T$ is injective if and only if $\nnull(T) = \{0\} = \range(T^*)^{\perp}$ if and only if $\range(T^*) = V$.
$T$ is surjective if and only if $\range(T) = V = \nnull(T^*)^{\perp}$ if and only if $\nnull(T^*) = \{0\}$.


\subsubsection*{Exercise 7}

Prove that if $T \in \mathcal{L}(V, W)$, then
\begin{itemize}
\item[(a)] $\dim(\nnull(T^*)) = \dim(\nnull(T)) + \dim(W) - \dim(V)$.
\item[(b)] $\dim(\range(T^*)) = \dim(\range(T))$.
\end{itemize}

\subsubsection*{Solution}

By 7.6 we have $\nnull(T^*) = \range(T)^{\perp}$, so, using 6.51, $\dim(\nnull(T^*)) = \dim(\range(T)^{\perp}) = \dim(W) - \dim(\range(T))$.
The fundamental theorem of linear maps, 3.21, gives $\dim(\range(T)) = \dim(V) - \dim(\nnull(T))$.
We get (a) by combining the previous results
\begin{equation*}
    \begin{split}
        \dim(\nnull(T^*)) &= \dim(\range(T)^{\perp}) \\
            &= \dim(W) - \dim(\range(T))
            = \dim(\nnull(T)) + \dim(W) - \dim(V).
    \end{split}
\end{equation*}
For (b) we have something similar.
We have
\begin{equation*}
    \begin{split}
        \dim(\range(T^*)) &= \dim(\nnull(T)^{\perp}) \\
            &= \dim(V) - \dim(\nnull(T)) \\
            &= \dim(V) - \dim(V) + \dim(\range(T))
            = \dim(\range(T)).
    \end{split}
\end{equation*}


\subsubsection*{Exercise 8}

Suppose $A$ is an $m$-by-$n$ matrix with entries in $\mathbb{F}$.
Use Exercise 7A.b to prove that the row rank of $A$ equals the column rank of $A$.

\subsubsection*{Solution}

Let $T \in \mathcal{L}(V, W)$ such that $\mathcal{M}(T) = A$.
We have
\begin{equation*}
    \text{column rank } A
        = \dim(\range(T))
        = \dim(\range(T^*))
        = \text{column rank } A^*
        = \text{row rank } A.
\end{equation*}
Exercise 7A.b is used in the second equality, theorem 7.9 is used in the last equality.


\subsubsection*{Exercise 9}

Prove that the product of two self-adjoint operators on $V$ is self-adjoint if and only if the two operators commute.

\subsubsection*{Solution}

Suppose $(ST)^* = ST$, then $TS = (TS)^{**} = (S^*T^*)^* = (ST)^* = ST$.
Conversely, if $ST = TS$, then $(ST)^* = T^*S^* = TS = ST$.


\subsubsection*{Exercise 10}

Suppose $\mathbb{F} = \mathbb{C}$ and $T \in \mathcal{L}(V)$.
Prove that $T$ is self-adjoint if and only if $\langle Tv, v \rangle = \langle T^*v, v \rangle$, for all $v \in V$.

\subsubsection*{Solution}

If $T$ is self-adjoint, then $\langle Tv, v \rangle = \langle T^*v, v \rangle$, for all $v \in V$.
Conversely, suppose $\langle Tv, v \rangle = \langle T^*v, v \rangle$, for all $v \in V$.
Take $S = T^* - T$.
Note that $\langle Sv, v \rangle = \langle Tv, v \rangle - \langle T^*v, v\rangle = 0$.
So, by 7.13, $S = 0$, hence $T = T^*$.


\subsubsection*{Exercise 11}

Define an operator $S: \mathbb{F}^2 \to \mathbb{F}^2: (x, y) \mapsto (-y, x)$.
\begin{itemize}
\item[(a)] Find a formula for $S^*$.
\item[(b)] Show that $S$ is normal but not self-adjoint.
\item[(c)] Find all eigenvalues of $S$.
\end{itemize}

\subsubsection*{Solution}
The formula for $S^*$ is $S^*(x, y) = (y, -x)$.
Note that $SS^*(x, y) = (x, y)$ and $S^*S(x, y) = (x, y)$, so $S^*S = I = SS^*$, hence $S$ is normal but not self-adjoint.
To find all the eigenvalues of $S$ solve the equation $S(x, y) = (-y, x) = \lambda(x, y)$.
Hence $\lambda x = -y$ and $\lambda y = x$.
So $x = \lambda y = -\lambda^2 x$, hence $\lambda^2 = 1$ or $\lambda = \pm i$ if $\mathbb{F} = \mathbb{C}$.
For $\mathbb{F} = \mathbb{R}$ there are no eigenvalues of $S$.


\subsubsection*{Exercise 12}

An operator $B \in \mathcal{L}(V)$ is called skew if $B^* = -B$.
Suppose that $T \in \mathcal{L}(V)$.
Prove that $T$ is normal if and only if there exists commuting operators $A$ and $B$ such that $A$ is self-adjoint, $B$ is a skew operator, and $T = A + B$.

\subsubsection*{Solution}

If $T = A + B$, then
\begin{equation*}
    TT^* = (A + B)(A^* - B)
        = AA^* - AB + BA^* - B^2
        = A^2 - B^2,
\end{equation*}
and
\begin{equation*}
    T^*T = (A^* - B)(A + B)
        = A^*A + A^*B - BA - B^2
        = A^2 - B^2.
\end{equation*}
We see that $T$ is normal.
Conversely, suppose $T$ is normal.
Take $A = \frac{1}{2}(T + T^*)$ and $B = \frac{1}{2}(T - T^*)$.
Clearly, we have $A$ is self-adjoint, $B$ is skew, and $T = A + B$.
We check that $A$ and $B$ commute.
\begin{equation*}
    AB = \frac{1}{4}(T + T^*)*(T - T^*)
        = \frac{1}{4}(T^2 + T^*T - TT^* - (T^*)^2)
        = \frac{1}{4}(T^2 - (T^*)^2),
\end{equation*}
and
\begin{equation*}
    BA = \frac{1}{4}(T - T^*)(T + T^*)
        = \frac{1}{4}(T^2 + TT^* - T^*T - (T^*)^2)
        = \frac{1}{4}(T^2 - (T^*)^2).
\end{equation*}
So $AB = BA$.
Which yield the result we have to show.


\subsubsection*{Exercise 13}

Suppose $\mathbb{F} = \mathbb{R}$.
Define $\mathcal{A} \in \mathcal{L}(\mathcal{L}(V))$ by $\mathcal{A}T = T^*$ for all $T \in \mathcal{L}(V)$.
\begin{itemize}
    \item[(a)] Find all eigenvalues of $\mathcal{A}$.
    \item[(b)] Find the minimal polynomial of $\mathcal{A}$.
\end{itemize}

\subsubsection*{Solution}

\begin{itemize}
    \item[(a)] We must have $\mathcal{A}(T) = T^* = \lambda T$.
        Taking the adjoint on both sides, $T = (T^*)^* = \overline{\lambda} T^* = |\lambda|^2 T$.
        As $\mathbb{F} = \mathbb{R}$, we must have $\lambda = \pm 1$ as eigenvalues.
    \item[(b)] Note $\mathcal{A}^2(T) = \mathcal{A}(T^*) = (T^*)^* = T$, so the minimal polynomial is a multiple of $p(x) = x^2 - 1$.
        From (a) we know that $\mathcal{A}$ has two eigenvalues, so $p(x)$ must be the minimal polynomial of $\mathcal{A}$.
\end{itemize}


\subsubsection*{Exercise 14}

Define an inner product on $\mathcal{P}_2(\mathbb{R})$ by $\langle p, q \rangle = \int_0^1 p(x) q(x) dx$.
Define an operator $T \in \mathcal{L}(\mathcal{P}_2(\mathbb{R}))$ by $T(ax^2 + bx + c) = bx$.
\begin{itemize}
    \item[(a)] Show that with this inner product, the operator $T$ is not self-adjoint.
    \item[(b)] The matrix of $T$ with respoect to the basis $1, x, x^2$ is
        \begin{equation*}
            \begin{pmatrix}
                0 & 0 & 0 \\
                0 & 1 & 0 \\
                0 & 0 & 0
            \end{pmatrix}
        \end{equation*}
        This matrix equals its conjugate transpose, even though $T$ is not self-adjoint.
        Explain why this is not a contradiction.
\end{itemize}

\subsubsection*{Solution}

\begin{itemize}
    \item[(a)] Take $p(x) = a_1 x^2 + b_1 x + c_1$ and $q(x) = a_2 x^2 + b_2 x + c_2$.
        If $T$ is self-adjoint, we should have $\langle Tp, q \rangle = \langle p, T^*q \rangle = \langle p, Tq \rangle$.
        We calculate
        \begin{equation*}
            \begin{split}
                \langle Tp, q \rangle
                    &= \int_0^1 Tp(x) q(x) dx
                    = \frac{1}{4} b_1 a_2 + \frac{1}{3} b_1 b_2 + \frac{1}{2} b_1 c_2, \\
                \langle p, Tq \rangle
                    &= \int_0^1 p(x) Tq(x) dx
                    = \frac{1}{4} a_1 b_2 + \frac{1}{3} b_1 b_2 + \frac{1}{2} c_1 b_2.
            \end{split}
        \end{equation*}
        So, in general, $\langle Tp, q \rangle \neq \langle p, Tq \rangle$.
    \item[(b)] For Theorem 7.9 to hold the basis in which the matrix is expressed needs to be orthonormal.
        The basis $\{1, x, x^2\}$ is not orthonormal.
\end{itemize}


\subsubsection*{Exercise 15}

Suppose $T \in \mathcal{L}(V)$ is invertible. Prove that
\begin{itemize}
\item[(a)] $T$ is self adjoint if and only if $T^{-1}$ is self-adjoint.
\item[(b)] $T$ is normal if and only if $T^{-1}$ is normal.
\end{itemize}

\subsubsection*{Solution}

We have $T = T^*$ if and only if $T^{-1} = (T^*)^{-1} = (T^{-1})^*$, by 7.5.f, which gives (a) immediately.
For (b) note that, it $T^{-1}$ is normal, $TT^* = ((T^*)^{-1}T^{-1})^{-1} = (T^{-1}(T^*)^{-1})^{-1} = T^*T$.
Conversely, substitute $T \leftarrow T^{-1}$ to get that if $T$ is normal than $T^{-1}$ is normal.


\subsubsection*{Exercise 16}

Suppose $\mathbb{F} = \mathbb{R}$.
\begin{itemize}
\item[(a)] Show that the set of self-adjoint operators on $V$ is a subspace of $\mathcal{L}(V)$.
\item[(b)] What is the dimension of the subspace of $\mathcal{L}(V)$ in (a)?
\end{itemize}

\subsubsection*{Solution}

Let $U = \{ T \in \mathcal{L}(V) : T^* = T \}$.
Let $S, T \in U$ and $\mu, \lambda \in \mathcal{F}$.
We have $(\mu S + \lambda T)^* = \mu S^* + \lambda T^* = \mu S + \lambda T$, so $\mu S + \lambda T \in U$.
Clearly $0 \in U$, so $U$ is a subspace of $\mathcal{L}(V)$.
A basis for $U$ is given by $\{e_{ij} + e_{ji}\}_{i \geq j}$.
Therefore, the dimension of $U$ is $\frac{1}{2}n(n+1)$.


\subsubsection*{Exercise 17}

Suppose $\mathbb{F} = \mathbb{C}$.
Show that the set of self-adjoint operators on $V$ is not a subspace of $\mathcal{L}(V)$.

\subsubsection*{Solution}

Note that $(i S)^* = \overline{i} S^* = -i S \neq i S$ if $S$ is a non-zero self-adjoint operator.


\subsubsection*{Exercise 18}

Suppose $\dim(V) \geq 2$.
Show that the set of normal operators on $V$ is not a subspace of $\mathcal{L}(V)$.

\subsubsection*{Solution}

TODO


\subsubsection*{Exercise 19}

Suppose $T \in \mathcal{L}(V)$ and $||T^*v|| \leq ||Tv||$ for every $v \in V$.
Prove that $T$ is normal.

\subsubsection*{Solution}

If $v \in \nnull(T)$ then $||T^*v|| \leq ||Tv|| = 0$, so $||T^*v|| = 0$, hence $\nnull(T^*) \subseteq \nnull(T)$.
Since $V$ is finite dimensional, using 6.49, $V = \range(T) \oplus (\range(T))^{\perp}$.
We have
\begin{equation*}
    V = \range(T) \oplus \range(T)^{\perp}
        = \range(T) \oplus \nnull(T^*)
        \subseteq \range(T) \oplus \nnull(T)
        \subseteq V
\end{equation*}
Hence, $\nnull(T^*) = \nnull(T)$.
From 7.21 it follows that $T$ is normal.


\subsubsection*{Exercise 20}

Suppose $P \in \mathcal{L}(V)$ is such that $P^2 = P$.
Prove that the following are equivalent: (a) $P$ is self-adjoint. (b) $P$ is normal. (c) There is a subspace $U$ of $V$ such that $P = P_U$.

\subsubsection*{Solution}

TODO


\subsubsection*{Exercise 21}

Suppose $D: \mathcal{P}_8(\mathbb{R}) \to \mathcal{P}_8(\mathbb{R})$ is the differentiation operator defined by $Dp = p'$.
Prove that there does not exist an inner product on $\mathcal{P}_8(\mathbb{R})$ that makes $D$ a normal operator.

\subsubsection*{Solution}

Note that $\range(T) \oplus \nnull(T) = \mathcal{P}_7(\mathbb{R}) \oplus \mathbb{R} \neq \mathcal{P}_8(\mathbb{R})$.
So $D$ can never be normal.


\subsubsection*{Exercise 22}

Give an example of an operator $T \in \mathbb{R}^3$ such that $T$ is normal but not self-adjoint.

\subsubsection*{Solution}

Extend example 7.19 to $\mathbb{R}^3$.
For example $T(x, y, z) = (2x - 2y, 3x + 2x, z)$.


\subsubsection*{Exercise 23}

Suppose $T$ is a normal operator on $V$.
Suppose also that $v, w \in V$ satisfy the equations $||v|| = ||w|| = 2$, $Tv = 3v$, and $Tw = 4w$.
Show that $||T(v + w)|| = 10$.

\subsubsection*{Solution}

Note that $v$ and $w$ are eigenvectors of $T$.
By 7.22, all eigenvectors with different eigenvalues are orthogonal, so $\langle v, w \rangle = 0$.
Therefore, we have $||T(v + w)||^2 = ||Tv||^2 + ||Tw||^2 = 3^2 ||v||^2 + 3^2 ||w||^2 = 100$.
So, $||T(v + w)|| = \sqrt{100} = 10$.


\subsubsection*{Exercise 24}

Suppose $T \in \mathcal{V}$ and $a_0 + a_1 x + ... + a_n x^n$ is the minimal polynomial of $T$.
Prove that the minimal polynomial of $T^*$ is $\overline{a_0} + \overline{a_1} x + ... + \overline{a_n} x^n$.

\subsubsection*{Solution 24}

By 5.27, the minimal polynomial of $T$ has the form $(x - \lambda_1)(x - \lambda_2)...(x - \lambda_n)$, where $\lambda_1, \lambda_2, ..., \lambda_n$ are the eigenvalues of $T$.
By exercise 7A.3, $\lambda_i$ is an eigenvalue of $T$ if and only if $\overline{\lambda_i}$ is an eigenvalue of $T^*$.
So, the minimal polynomial of $T^*$ is $(x - \overline{\lambda_1})(x - \overline{\lambda_2})...(x - \overline{\lambda_n})$.
Expanding the product we see that
\begin{equation*}
    \prod_{i = 1}^n (x - \overline{\lambda_i})
        = \overline{a_0} + \overline{a_1}x + ... + \overline{a_n} x^n.
\end{equation*}


\subsubsection*{Exercise 7A.25}

Suppose $T \in \mathcal{L}(V)$.
Prove that $T$ is diagonal if and only if $T^*$ is diagonal.

\subsubsection*{Solution}

From the previous exercise we know that $\prod_{i=1}^n (z - \lambda_i)$ is the minimal polynomial of $T$ if and only if $\prod_{i=1}^n (z - \overline{\lambda_i})$ is the minimal polynomial of $T^*$.
From 5.62 it follows that $T$ is diagonal if and only if $T^*$ is diagonal.


\subsubsection*{Exercise 7A.26}

Fix $u, v \in V$.
Define $T \in \mathcal{L}(V)$ by $Tv = \langle u, v \rangle x$ for every $v \in V$.
\begin{itemize}
    \item[(a)] Prove that if $V$ is a real vector space, then $T$ is self-adjoint if and only if the list $u, x$ is linearly independent.
    \item[(b)] Prove that $T$ is normal if and only if the list $u, x$ is linearly dependent.
\end{itemize}

\subsubsection*{Solution}

Note that
\begin{equation*}
    \langle v_1, T^* v_2 \rangle
        = \langle Tv_1, v_2 \rangle
        = \langle v_1, u \rangle \langle x, v_2 \rangle
        = \langle v_1, \overline{\langle x, v_2 \rangle} u \rangle,
\end{equation*}
so, $T^*v = \overline{\langle x, v\rangle} u = \langle v, x \rangle u$.

\begin{itemize}
    \item[(a)] $\rightarrow$, Suppose $T^* = T$.
        Then $\langle v, u \rangle x = \langle v, x \rangle u$ for all $v \in V$, so $x$ and $u$ are linear dependent as they are a scalar difference of each other.
        $\leftarrow$, Suppose $u$ and $x$ are linear dependent, i.e., $u = \lambda x$ for some $\lambda \in \mathbb{R}$ ($V$ is a real vector space).
        We have
        \begin{equation*}
            T^*v = \langle v, x \rangle u
                = \lambda \langle v, x \rangle x
                = \langle v, u \rangle x
                = Tv.
        \end{equation*}
    \item[(b)] $\rightarrow$, Suppose $T$ is normal.
        \begin{equation*}
            \langle x, v \rangle \langle u, u \rangle x
                = \langle v, x \rangle Tu
                = TT^* v
                = T^*T v
                = \langle v, u \rangle Tx
                = \langle v, u \rangle \langle x, x \rangle u.
        \end{equation*}
        So $x$ and $u$ are linear dependent as they are a scalar difference of each other.
        $\leftarrow$, Suppose $u = \lambda x$, then
        \begin{equation*}
            TT^*v
                = \langle x, v \rangle \langle u, u \rangle x
                = \langle x, v \rangle \langle x, x \rangle |\lambda|^2 x
                = \langle x, \lambda v \rangle \langle x, x \rangle \lambda x
                = \langle x, u \rangle \langle x, x \rangle u
                = T^*Tv,
        \end{equation*}
        for all $v \in V$.
\end{itemize}


\subsubsection*{Exercise 7A.27}

Suppose $T \in \mathcal{L}(V)$ is normal.
Prove that $\nnull(T^k) = \nnull(T)$ and $\range(T^k) = \range(T)$ for every positive integer $k$.

\subsubsection*{Solution}

It's clear that $\null(T) \subseteq \nnull(T^k)$.
If $k = 1$ there is nothing to prove.
Suppose $k > 1$.
Let $v \in \nnull(T^k)$, hence $T^k v = 0$, then $T^{k-1}v \in \nnull(T) = \nnull(T^*)$ by 7.21.
Because $k > 1$, we have $T^{k-1}v \in \range(T)$.
By 7.6 $\null(T^*) = \range(T)^{\perp}$, so $T^{k-1}v \in \range(T) \cap \range(T)^{\perp} = \{0\}$.
Therefore $T^{k-1}v = 0$.
By induction on $k$ we see $v \in \nnull(T)$.

For the second statement, note that if $T$ is normal, then $T^k$ is normal.
So by 7.21,
\begin{equation*}
    \nnull(T) \oplus \range(T) = V = \nnull(T^k) \oplus \range(T^k) = \nnull(T) \oplus \range(T^k),
\end{equation*}
so we must have $\range(T) = \range(T^k)$.


\subsubsection*{Exercise 7A.28}

Suppose $T \in \mathcal{V}$ is normal.
Prove that if $\lambda \in \mathbb{F}$, then the minimal polynomial of $T$ is not a polynomial multiple of $(x - \lambda)^2$.

\subsubsection*{Solution}

Suppose the contrary.
If the minimal polynomial of $T$ is a polynomial multiple of $(x - \lambda)^2$, then there are two distinct eigenvectors with the same eigenvalue $\lambda$.
But this contradicts 7.22.


\subsubsection*{Exercise 7A.29}

Prove or give a counterexample.
If $T \in \mathcal{L}(V)$ and there is an orthonormal basis $e_1, e_2, ..., e_n$ of $V$ such that $\norm{Te_k} = \norm{T^*e_k}$ for each $k = 1, 2, ..., n$, then $T$ is normal.

\subsubsection*{Solution}

This is not true.
Take $V = \mathbb{R}^2$, $e_1, e_2$ the standard basis, and define $T \in \mathcal{L}(V)$ by $Te_1 = e_1 + e_2$ and $Te_2 = -e_1 - e_2$.
Then $T^*e_1 = e_1 - e_2$, $T^*e_2 = e_1 - e_2$, so $\norm{Te_1} = \sqrt{2} = \norm{T^*e_1}$ and $\norm{Te_2} = \sqrt{2} = \norm{T^*e_2}$.
But $TT^*e_1 = 0$ and $T^*Te_1 = 2e_1 - 2e_2$.
So, $T$ is not normal.


\subsubsection*{Exercise 7A.30}

Suppose that $T \in \mathcal{L}(V)$ is normal and $T(1, 1, 1) = (2, 2, 2)$.
Suppose $(z_1, z_2, z_3) \in \nnull(T)$.
Prove that $z_1 + z_2 + z_3 = 0$.

\subsubsection*{Solution}

Because $T$ is normal, $\nnull(T) = \nnull(T^*)$, so $(z_1, z_2, z_3) \in \nnull(T^*)$.
We have
\begin{equation*}
    2(z_1 + z_2 + z_3)
        = \langle (z_1, z_2, z_3), (2, 2, 2) \rangle
        = \langle (z_1, z_2, z_3), T(1, 1, 1) \rangle
        = \langle T^*(z_1, z_2, z_3), (1, 1, 1) \rangle
        = \langle 0, (1, 1, 1) \rangle
        = 0,
\end{equation*}
hence $z_1 + z_2 + z_3 = 0$.


\subsubsection*{Exercise 7A.31}

Fix a positive integer $n$.
In the inner product space of continuous real-valued functions on $A = [-\pi, \pi]$ with inner product $\langle f, g \rangle = \int_A f(x)g(x) dx$, let
\begin{equation*}
    V = \mathrm{span}(1, \cos(x), \cos(2x), ..., \cos(nx), \sin(x), \sin(2x), ..., \sin(nx)).
\end{equation*}
\begin{itemize}
    \item[(a)] Define $D \in \mathcal{L}(V)$ by $Df = f'$.
        Show that $D^* = -D$.
        Conclude that $D$ is normal but not self-adjoint.
    \item[(b)] Define $T \in \mathcal{L}(V)$ by $Tf = f''$.
        Show that $T$ is self-adjoint.
\end{itemize}

\subsubsection*{Solution}

\begin{itemize}
    \item[(a)] Showing that $D^* = -D$ is equivalent to showing that $\langle Df, g\rangle = \int_A f'(x)g(x)dx = - \int_A f(x)g'(x)dx = \langle f, -Dg \rangle$.
        We can calculate this by evaluating $\langle Df, g \rangle$ on all basis elements $1, \cos(kx), \sin(\ell x)$.
        TODO: do the calculations.
        Note that if $D^* = -D$, then $D^*D = -D^2 = DD^*$.
        So $D$ is normal, but not self-adjoint.
    \item[(b)] We have $T^* = (D^2)* = (D^*)^2 = (-D)^2 = D^2 = T$.
        So, $T$ is self-adjoint.
\end{itemize}


\subsubsection*{Exercise 7A.32}

Suppose $T: V \to W$ is a linear map.
Show that under the standard identification of $V$ with $V'$ (see 6.58) and the corresponding identification of $W$ with $W'$, the adjoint map $T^*: W \to V$ corresponds to the dual map $T': W' \to V'$.
More precisely, show that $T'(\phi_w) = \phi_{T^*w}$ for all $w \in W$, where $\phi_w$ and $\phi_{T^*w}$ are defined as in 6.58.

\subsubsection*{Solution}

We have
\begin{equation*}
    T'(\phi_w)(v)
        = \phi_w(T(v))
        = \langle T(v), w \rangle
        = \langle v, T^*(w) \rangle
        = \phi_{T^*(w)}(v).
\end{equation*}


\subsection*{Section 7B - Spectral Theorem}

\subsubsection*{Exercise 7B.1}

Prove that a normal operator on a complex inner product space is self-adjoint if and only if all its eigenvalues are real.

\subsubsection*{Solution}

Let $T \in \mathcal{L}(V)$ be a normal operator.
By the Spectral Theorem, 7.31, there is a orthonormal basis such that $\mathcal{M}(T)$ is diagonal.
The diagonal elements of $\mathcal{M}(T)$ are the eigenvalues of $T$.
By 7.9 we have $\mathcal{M}(T^*) = \mathcal{M}(T)^*$.
Hence, $T^* = T$ if and only if $\mathcal{M}(T) = \mathcal{M}(T)^*$ if and only if the diagonal of $\mathcal{M}(T)$ only has real values if and only if the eigenvalues of $T$ are real.


\subsubsection*{Exercise 7B.2}

Suppose $\mathbb{F} = \mathbb{C}$.
Suppose $T \in \mathcal{L}(V)$ is normal and has only one eigenvalue.
Prove that $T$ is a scalar multiple of the identity operator.

\subsubsection*{Solution}

Because $T$ is normal, we can apply the Spectral Theorem 7.31.
There is an orthogonal basis such that $\mathcal{M}(T)$ is diagonal with eigenvalues on the diagonal.
Because $T$ has only one eigenvalue $\lambda$, we must have $\mathcal{M}(T) = \lambda I$.
Therefore $T = \lambda I$.


\subsubsection*{Exercise 7B.3}

Suppose $\mathbb{F} = \mathbb{C}$ and $T \in \mathcal{L}(V)$ is normal.
Prove that the set of eigenvalues of $T$ is contained in $\{0, 1\}$ if and only if there is a subspace $U$ of $V$ such that $T = P_U$.

\subsubsection*{Solution}

By the Spectral Theorem we can find an orthonormal basis of $V$ such that $T$ is diagonal with respect to that basis.
The diagonal of that matrix contains the eigenvalues of $T$, and the basis corresponds to the eigenvectors of $T$.

$\rightarrow$, suppose all eigenvalues are $0$ or $1$.
Without loss of generality we can assume $\lambda_1 = \lambda_2 = ... = \lambda_k = 0$ and $\lambda_{k+1} = \lambda_{k+2} = ... = \lambda_n = 1$.
Take $U = \mathrm{span}(e_{k+1}, e_{k+2}, ..., e_n)$, such that $U^{\perp} = \mathrm{span}(e_1, e_2, ..., e_k)$ and $V = U \oplus U^{\perp}$.
Let $v \in V$ and write $v = u + w \in U \oplus U^{\perp}$, then $Tv = Tu + Tv = u = P_Uv$.
Hence, $T = P_U$.

$\leftarrow$, if $T = P_U$ for some subspace $U$ of $V$.
Let $\{e_1, e_2, ..., e_n\}$ be an orthonormal basis such that $U = \mathrm{span}(e_1, e_2, ..., e_k)$.
Then $Te_i = P_U e_i = e_i$ if $e_i \in U$ and $Te_i = 0$ if $e_i \notin U$.
So $\{e_1, e_2, ..., e_n\}$ are eigenvectors for $T$ with eigenvalues $0$ or $1$.


\subsubsection*{Exercise 7B.4}

Prove that a normal operator on a complex inner product space is skew if and only if all its eigenvalues are purely imaginary.

\subsubsection*{Solution}

Let $T \in \mathcal{L}(V)$ be a normal operator.
By the Spectra Theorem, 7.31, $T$ has a diagonal matrix with respect to some orthonormal basis of $V$.
If $T$ is skew, then $\mathcal{M}(T^*) = \mathcal{M}(T)^* = -\mathcal{M}(T)$.
Since $\mathcal{M}(T)$ is diagonal with eigenvalues on the diagonal, we have for each eigenvalue $\lambda_i$ that $\overline{\lambda_i} = -\lambda_i$.
This is only true if and only if $\lambda_i \in i\mathbb{R}$.
So $T$ is skew if and only if $\overline{\lambda_i} = -\lambda_i$ for all eigenvalues $\lambda_i$ if and only if all eigenvalues are purely imaginary.


\subsubsection*{Exercise 7B.5}

Prove or give a counterexample: If $T \in \mathcal{L}(\mathbb{C}^3)$ is a diagonalizable operator, then $T$ is normal (with respect to the usual inner product).

\subsubsection*{Solution}

Take
\begin{equation*}
T = \begin{pmatrix}
    1 & 1 & 0 \\
    0 & 2 & 0 \\
    0 & 0 & 1
\end{pmatrix}, \quad
S = \begin{pmatrix}
    1 & \frac{1}{2}\sqrt{2} & 0 \\
    0 & \frac{1}{2}\sqrt{2} & 0 \\
    0 & 0 & 1
\end{pmatrix}, \quad
S^{-1}TS = \begin{pmatrix}
    1 & 0 & 0 \\
    0 & 2 & 0 \\
    0 & 0 & 1
\end{pmatrix}.
\end{equation*}
So $T$ is diagonalizable.
However
\begin{equation*}
    TT^* = \begin{pmatrix}
        2 & 2 & 0 \\
        2 & 4 & 0 \\
        0 & 0 & 1
    \end{pmatrix}
    \neq
    \begin{pmatrix}
        1 & 1 & 0 \\
        1 & 4 & 0 \\
        0 & 0 & 1
    \end{pmatrix}
    = T^*T.
\end{equation*}


\subsubsection*{Exercise 7B.6}

Suppose $V$ is a complex inner product space and $T \in \mathcal{L}(V)$ is a normal operator such that $T^9 = T^8$.
Prove that $T$ is self-adjoint and $T^2 = T$.

\subsubsection*{Solution}

By the Spectral Theorem, 7.31, there is an orthonormal basis $\{v_i\}$ such that $Tv_i = \lambda_i v_i$.
We have $\lambda_i^9 v_i = T^9 v_i = T^8 v_i = \lambda_i^8 v_i$, so $\lambda_i^9 = \lambda_i^8$, so $\lambda_i^2 = \lambda_i$, which implies $\lambda_i \in \{0, 1\}$.
Because all eigenvalues are real, $T$ is self-adjoint.
Because the diagonal contains either $0$ or $1$ in the diagonal $\mathcal{M}(T)$, $T^2 = T$.


\subsubsection*{Exercise 7B.7}

Give an example of an operator $T$ on a complex vector space such that $T^9 = T^8$, but $T^2 \neq T$.

\subsubsection*{Solution}

Let $V = \mathbb{C}^2$ and take $Te_1 = 0$, $Te_2 = e_1$.
Then $T^2 = T^8 = T^9 = 0$, but $T \neq 0$.

Note that $T$ is not normal, because $T^*T \neq TT^*$.
This is why the result of 7B.6 fails in this case.


\subsubsection*{Exercise 7B.8}

Suppose $\mathbb{F} = \mathbb{C}$ and $T \in \mathcal{L}(V)$.
Prove that $T$ is normal if and only if every eigenvector of $T$ is also an eigenvector of $T^*$.

\subsubsection*{Solution}

$\rightarrow$, Because $T$ is normal we can use the Spectral Theorem 7.31 to find an orthonormal basis $e_1, e_2, ..., e_n$ such that $\mathcal{M}(T)$ is diagonal with elements $\lambda_1, \lambda_2, ..., \lambda_n$.
This orthonormal basis are the eigenvectors of $T$ with eigenvalues $\lambda_1, \lambda_2, ..., \lambda_n$.
Therefore, $\mathcal{T^*} = \mathcal{T}^*$, so $T^*$ has eigenvalues $\overline{\lambda_1}, \overline{\lambda_2}, ..., \overline{\lambda_n}$ with the same eigenvectors $e_1, e_2, ..., e_n$.

\noindent $\leftarrow$, Suppose $T$ and $T^*$ have the same eigenvectors.
By Schur's Theorem, 6.38, $T$ has an orthonormal basis $e_1, e_2, ..., e_n$ such that $\mathcal{M}(T)$ is an upper triangular matrix.
Let $\mathcal{M}(T) = A = (a_{ij})_{i,j}$.
Note that if $Te_i = \sum_{j=0}^n a_{ij} e_j$, then $T^*e_j = \sum_{j = 0}^n \overline{a_{ji}} e_j$.
We have that $Te_1 = a_{11} e_1$ is an eigenvector of $T$, so $e_1$ is an eigenvector of $T^*$, hence $T^*e_1 = \sum_{j = 0}^n \overline{a_{ji}} e_j = \overline{a_{11}} e_1$.
So we must have $a_{j1} = 0$ for all $j > 1$.
By induction on $i$ in $e_i$ we fined that all $a_{ji} = 0$ if $j > i$.
Hence $A$ is diagonal with respect to orthonormal basis $e_1, e_2, ..., e_n$.
By the Spectral Theorem, 7.31, $T$ is normal.


\subsubsection*{Exercise 7B.9}

Suppose $\mathbb{F} = \mathbb{C}$ and $T \in \mathcal{L}(V)$.
Prove that $T$ is normal if and only if there exists a polynomial $p \in \mathcal{P}(\mathbb{C})$ such that $T^* = p(T)$.

\subsubsection*{Solution}

$\rightarrow$, Suppose $T$ is normal.
We can use the Spectral Theorem, 7.31, to find an orthonormal basis of eigenvectors $v_1, v_2, ..., v_n$ such that $\mathcal{M}(T)$ is diagonal with eigenvalues $\lambda_1, \lambda_2, ..., \lambda_n$ on the diagonal.
Additionally, we have that $\mathcal{M}(T^*) = \mathcal{M}(T)^*$ is diagonal with eigenvalues $\overline{\lambda_1}, \overline{\lambda_2}, ..., \overline{\lambda_n}$ on the diagonal.
Define
\begin{equation*}
    \phi_j(x) = \prod_{i = 1, i \neq j}^{n} \left( \frac{x - \lambda_i}{\lambda_j - \lambda_i} \right).
\end{equation*}
Note that $\phi_j(T)v_i = \delta_{ij}$.
The vector space $V$ decomposes into $V = E(T, \lambda_1) \oplus E(T, \lambda_2) \oplus ... \oplus E(T, \lambda_n)$.
Let $v \in V$, then $v = a_1 v_1 + a_2 v_2 + ... + a_n v_n$.
Then $\phi_j(T)v = a_j v_j$.
Define
\begin{equation*}
    p(x) = \overline{\lambda_1} \phi_1(x) + \overline{\lambda_2} \phi_2(x) + ... + \overline{\lambda_n}(x).
\end{equation*}
We have
\begin{equation*}
    p(T)v = \overline{\lambda_1} \phi_1(T)v + \overline{\lambda_2} \phi_2(T)v + ... + \overline{\lambda_n}(T)v
        = a_1 \overline{\lambda_1} v_1 + a_2 \overline{\lambda_2} v_2 + ... + a_n \overline{\lambda_2} v_n
        = T^* v.
\end{equation*}
So $T^* = p(T)$.

$\leftarrow$, If $T^* = p(T)$, then $T^* T = p(T)T = Tp(T) = TT^*$.


\subsubsection*{Exercise 7B.10}

Suppose $V$ is a complex inner product space.
Prove that every normal operator on $V$ has a square root.

\subsubsection*{Solution}

According to the Spectral Theorem, 7.31, there exists an orthonormal basis $v_1, v_2, ..., v_n$ such that $T$ is diagonal and $Tv_i = \lambda_i v_i$.
Define $S \in \mathcal{L}(V)$ by $Sv_i = \sqrt{\lambda_i} v_i$.
Then $S^2 = T$.


\subsubsection*{Exercise 7B.11}

Prove that every self-adjoint operator on $V$ has a cube root.

\subsubsection*{Solution}

According to the Spectral Theorem, 7.29 or 7.31, there exists an orthonormal basis $v_1, v_2, ..., v_n$ such that $T$ is diagonal and $Tv_i = \lambda_i v_i$.
Define $S \in \mathcal{L}(V)$ by $Sv_i = \lambda_i^{\frac{1}{3}} v_i$.
Then $S^3 = T$.

Note that every self-adjoint operator has any possible root using exactly the same method.


\subsubsection*{Exercise 7B.12}

Suppose $V$ is a complex vector space and $T \in \mathcal{L}(V)$ is normal.
Prove that if $S$ is an operator on $V$ that commutes with $T$, then $S$ commutes with $T^*$.

\subsubsection*{Solution}

Because $T$ is normal, according to Exercise 7B.9, there exists a polynomial such that $T^* = p(T)$.
Therefore, $ST^* = Sp(T) = p(T)S = T^*S$.


\subsubsection*{Exercise 7B.13}

Without using the complex spectral theorem, use the version of Schur's Theorem that applies to two commuting operators to give a different proof that if $\mathbb{F} = \mathbb{C}$ and $T \in \mathcal{L}(V)$ is normal, then $T$ has a diagonal matrix with respect to some orthonormal basis of $V$.

\subsubsection*{Solution}

Let $\mathcal{E} = \{T, T^*\}$.
Because $T$ is normal $\mathcal{E}$ is a set of commuting operators.
By Schur's Theorem, Exercise 6B.20, there is an orthonormal basis such that every element in $\mathcal{E}$ has an upper-triangular matrix.
Note that $\mathcal{M}(T)$ and $\mathcal{M}(T^*) = \mathcal{M}(T)^*$ are both an upper-triangular matrix.
But this is only possible when $\mathcal{M}(T)$ is a diagonal matrix.


\subsubsection*{Exercise 7B.14}

Suppose $\mathbb{F} = \mathbb{R}$ and $T \in \mathcal{L}(V)$.
Prove that $T$ is self-adjoint if and only if all pairs of eigenvectors corresponding to distinct eigenvalues of $T$ are orthogonal and $V = E(\lambda_1, T) \oplus E(\lambda_2, T) \oplus ... \oplus E(\lambda_m, T)$, where $\lambda_1, \lambda_2, ..., \lambda_m$ denote the distinct eigenvalues of $T$.

\subsubsection*{Solution}

$\rightarrow$, Suppose $T$ is self-adjoint.
By the Spectral Theorem, 7.29, there exists an orthonormal basis of eigenvectors of $T$ such that $T$ has a diagonal matrix.
Therefore, $V = E(\lambda_1, T) \oplus E(\lambda_2, T) \oplus ... \oplus E(\lambda_m, T)$.
Let $\lambda_i$ and $\lambda_j$ distinct eigenvalues of $T$.
Take $v \in E(\lambda_i, T)$ and $w \in E(\lambda_j, T)$, then $\lambda_i \langle v, w \rangle = \langle \lambda_i v, w \rangle = \langle Tv, w \rangle = \langle v, Tw \rangle = \langle v, \lambda_j w \rangle = \lambda_j \langle v, w \rangle$.
So we must have $\langle v, w \rangle = 0$.
This shows all the requirements.

$\leftarrow$, Because $V = E(\lambda_1, T) \oplus E(\lambda_2, T) \oplus ... \oplus E(\lambda_m, T)$, by Theorem 5.55, $V$ has a basis of eigenvectors for which $T$ has a diagonal matrix.
Since the eigenvectors of distinct eigenvalues are orthogonal, by the Spectral Theorem 7.29, $T$ is self-adjoint.


\subsubsection*{Exercise 7B.15}

Suppose $\mathbb{F} = \mathbb{C}$ and $T \in \mathcal{L}(V)$.
Prove that $T$ is normal if and only if all pairs of eigenvectors corresponding to distinct eigenvalues of $T$ are orthogonal and $V = E(\lambda_1, T) \oplus E(\lambda_2, T) \oplus ... \oplus E(\lambda_m, T)$, where $\lambda_1, \lambda_2, ..., \lambda_m$ denote the distinct eigenvalues of $T$.

\subsubsection*{Solution}

The proof is similar to Exercise 7B.14, but now using the complex Spectral Theorem 7.31.


\subsection*{Section 7D - Isometries, Unitary Operators, and Matrix Factorization}

\subsubsection*{Exercise 7D.12}

Prove or give a counterexample: If $S \in \mathcal{L}(V)$ is invertible and $\norm{S^{-1}v} = \norm{Sv}$ for every $v \in V$, then $S$ is unitary.

\subsubsection*{Solution}

This is false.
If $S$ is unitary, we must have $S^* = S^{-1}$.
Take
\begin{equation*}
    S = \begin{pmatrix}
        -1 & -i \\
        i & 1
    \end{pmatrix},
\end{equation*}
then
\begin{equation*}
    S^{-1}
        = \begin{pmatrix}
            1 & i \\
            -i & -1
        \end{pmatrix}
        \neq \begin{pmatrix}
            -1 & -i \\
            i & 1
        \end{pmatrix}
        = S^*,
\end{equation*}
while
\begin{equation*}
    \norm{Sv}
        = \norm{\begin{pmatrix}
            -v_1 - iv_2 \\
            iv_1 + v_2
        \end{pmatrix}}
        = \sqrt{(v_1 + iv_2)^2 + (iv_1 + v_2)^2}
        = \norm{\begin{pmatrix}
            v_1 + iv_2 \\
            -iv_1 - v_2
        \end{pmatrix}}
        = \norm{S^{-1}v}.
\end{equation*}


\subsubsection*{Exercise 7D.13}

Explain why the columns of a square matrix of complex numbers form an orthonormal list in $\mathbb{C}^n$ if and only if the rows of the matrix form an orthonormal list in $\mathbb{C}^n$.

\subsubsection*{Solution}

Let $A$ be a square matrix with orthonormal columns.
We have $AA^t = I$, so $A^{-1} = A^t$ and $AA^t = AA^{-1} = I$.
So, $A^t$ has orthonormal columns.
But that means that $A$ has orthonormal rows.


\subsubsection*{Exercise 7D.15}

Suppose $T$ is a unitary operator on $V$ such that $T - I$ is invertible.
Prove that $S = (T + I)(T - I)^{-1}$ is a skew operator.
Prove that if $\mathbb{F} = \mathbb{C}$, then $iS$ is a self-adjoint operator.


\subsubsection*{Solution}

Note that $T + I$ and $T - I$ commute, so $(T - I)^{-1}$ and $T + I$ commute as well.
We have
\begin{equation*}
    \begin{split}
        S^* &= (T^* + I^*)^{-1}(T^* - I^*) \\
            &= (T^{-1} + I)^{-1}(T^{-1} - I) \\
            &= (T^{-1}(I + T))^{-1}(T^{-1} - I) \\
            &= (T + I)^{-1} T(T^{-1} - I) \\
            &= (T + I)^{-1} (I - T) \\
            &= - (T - I)(T + I)^{-1} = -S.
    \end{split}
\end{equation*}
Note that if $\mathbb{F} = \mathbb{C}$, then $(iS)^* = -\overline{i}S = iS$.
So, $iS$ is self-adjoint.


\subsubsection*{Exercise 7D.16}

Suppose $\mathbb{F} = \mathbb{C}$ and $T \in \mathcal{L}(V)$ self-adjoint.
Prove that $S = (T + iI)(T - iI)^{-1}$ is a unitary operator and $1$ is not an eigenvalue of this operator.

\subsubsection*{Solution}

Note that $T + iI$ and $T - iI$ commute, so $(T + iI)(T - iI)^{-1} = (T - iI)^{-1}(T + iI)$ and $(T + iI)^{-1}(T - iI) = (T - iI)(T + iI)^{-1}$.
We calculate
\begin{equation*}
    S^*
        = (T^* - (iI)^*)^{-1} (T^* + (iI)^*)
        = (T + iI)^{-1} (T - iI)
        = (T - iI) (T + iI)^{-1}.
\end{equation*}
Therefore we see that $S^*S = I = SS^*$, hence by 7.53, $S$ is a unitary operator.

Suppose $v \in V$ such that $Sv = v$, then $(T + iI)v = (T - iI)v$, hence $iv = -iv$, which is impossible.
So there is no eigenvector with eigenvalue $1$.


\subsubsection*{Exercise 7D.18}

A square matrix $A$ is called symmetric if it equals its transpose.
Prove that if $A$ is a symmetric matrix with real entries, then there exists a unitary matrix $Q$ with real entries such that $Q^*AQ$ is a diagonal matrix.

\subsubsection*{Solution}

We identify square matrix $A$ with its corresponding operator $A \in \mathcal{L}(V)$, and abuse notation by writing the same letter.
If $A$ has real entries, we can consider $V$ to be a real vector space.
As $A$ equals its transpose, $A^* = A$, so $A$ is self-adjoint.
By the Spectral Theorem for real vector spaces $A = Q^*AQ$, where $Q$ is a unitary matrix with real entries.


\subsubsection*{Exercise 7D.19}

Suppose $n$ is a positive integer.
Let $V = \mathbb{C}^n$ and any element $z \in \mathbb{C}^n$ is denoted by $z = (z_0, z_1, ..., z_{n-1})$.
Define linear functionals $\omega_0, \omega_1, ..., \omega_{n-1}$ on $V$ by
\begin{equation*}
    \omega_j(z) = \frac{1}{\sqrt{n}} \sum_{k=0}^{n-1} z_k e^{-i 2 \pi j \frac{k}{n}}.
\end{equation*}
The discrete Fourier transform is the operator $\mathcal{F}: V \to V$ defined by $\mathcal{F}(z) = (\omega_0(z), \omega_1(z), ..., \omega_{n-1}(z))$.

\begin{itemize}
    \item[(a)] Show that $\mathcal{F}$ is a unitary operator on $V$.
    \item[(b)] Show that if $z \in V$ then $\mathcal{F}^{-1}(z) = \mathcal{F}(z_0, z_{n-1}, ..., z_1)$.
    \item[(c)] Show that $\mathcal{F}^4 = I$.
\end{itemize}

\subsubsection*{Solution}

First note that if we take integers $m_1$ and $m_2$, then
\begin{equation*}
    \sum_{j = 0}^{n-1} e^{-i 2 \pi j \frac{m_1 - m_2}{n}}
        = \sum_{j = 0}^{n-1} \left( e^{-i 2 \pi \frac{m_1 - m_2}{n}} \right)^j
        = \frac{1 - e^{-i 2 \pi (m_1 - m_2)}}{1 - e^{-i 2 \pi \frac{m_1 - m_2}{n}}}
        = \delta_{m_1, m_2}.
\end{equation*}
With this equation we have
\begin{equation*}
    \begin{split}
        \norm{\mathcal{F}(x)}^2
            &= \sum_{j = 0}^{n-1} \omega_j(z) \overline{\omega_j(z)} \\
            &= \sum_{j = 0}^{n-1} \sum_{m_1 = 0}^{n-1} \sum_{m_2 = 0}^{n-1} \frac{1}{n} z_{m_1} \overline{z_{m_2}} e^{-i 2 \pi j \frac{m_1}{n}} \overline{e^{-i 2 \pi j \frac{m_2}{n}}} \\
            &= \sum_{j = 0}^{n-1} \sum_{m_1 = 0}^{n-1} \sum_{m_2 = 0}^{n-1} \frac{1}{n} z_{m_1} \overline{z_{m_2}} e^{-i 2 \pi j \frac{m_1 - m_2}{n}} \\
            &= \sum_{m_1 = 0}^{n-1} \sum_{m_2 = 0}^{n-1} \frac{1}{n} z_{m_1} \overline{z_{m_2}} \sum_{j = 0}^{n-1} e^{-i 2 \pi j \frac{m_1 - m_2}{n}} \\
            &= \sum_{m_1 = 0}^{n-1} \sum_{m_2 = 0}^{n-1} \frac{1}{n} z_{m_1} \overline{z_{m_2}} \delta_{m_1, m_2} \\
            &= \sum_{m = 0}^{n-1} z_{m} \overline{z_{m}}
            = \norm{z}^2.
    \end{split}
\end{equation*}
So $\mathcal{F}$ is an isometry.
If $z = 0$, then $\norm{\mathcal{F}(z)} = \norm{z} = 0$, so $\mathcal{F}(z) = 0$.
Therefore $\mathcal{F}$ is injective, and because $V$ is finite dimensional, $\mathcal{F}$ is invertible.
This show (a), i.e., $\mathcal{F}$ is a unitary operator on $V$.

I think I don't see the trick the author is suggesting in (b).
Instead, I calculate the result brute force.
Applying $\mathcal{F}$ on both sides, and re-parameterize the indices yields that we must show that
\begin{equation*}
    \mathcal{F}^2(z) = (z_0, z_{n-1}, z_{n-2}, ..., z_1).
\end{equation*}
Note that this is the same as showing that $\mathcal{M}{\mathcal{F}^2}_{\ell k} = 1$ if $\ell + k = 0$ mod $n$, and $0$ if $\ell + k \neq 0$ mod $n$.
Let $v_{\ell}$ be the $\ell$-th column of the matrix $\mathcal{M}(\mathcal{F})$, then $\mathcal{M}{\mathcal{F}^2}_{\ell k} = v_{\ell}^t v_k$.
If $\ell + k = 0$ modulo $n$, we have
\begin{equation*}
    v_{\ell}^t v_k = \sum_{j = 0}^{n - 1} \frac{1}{n} e^{-i 2 \pi j \frac{\ell}{n}} e^{-i 2 \pi j \frac{k}{n}}
        = \sum_{j = 0}^{n - 1} \frac{1}{n} e^{-i 2 \pi j \frac{\ell + k}{n}}
        = 1.
\end{equation*}
If $\ell + k \neq 0$ modulo $n$, we have
\begin{equation*}
    v_{\ell}^t v_k
        = \sum_{j = 0}^{n - 1} \frac{1}{n} e^{-i 2 \pi j \frac{\ell + k}{n}}
        = \sum_{j = 0}^{n - 1} \frac{1}{n} \left( e^{-i 2 \pi \frac{\ell + k}{n}} \right)^j
        = \frac{1}{n} \frac{1 - e^{-i 2 \pi (\ell + k)}}{1 - e^{-i 2 \pi \frac{k + \ell}{n}}}
        = 0.
\end{equation*}
This gives the result.

For (c) use the result of (b), i.e., $\mathcal{F}^2(z) = (z_0, z_{n-1}, z_{n-2}, ..., z_1)$, so that $\mathcal{F}^4(z) = z$.


\subsubsection*{Exercise 7D.20}

Suppose $A$ is a square matrix with linearly independent columns.
Prove that there exists unique matrices $R$ and $Q$ such that $T$ is lower triangular with only positive numbers on its diagonal, $Q$ unitary, and $A = RQ$.

\subsubsection*{Solution}

If $A$ is a square matrix with linearly independent columns, $A^*$ is also a square matrix with linearly independent columns.
Apply the $QR$-decomposition on $A^*$ such that $A^* = QR$, where $Q$ is a unitary matrix and $R$ an upper triangular matrix with positive numbers on its diagonal.
Note that $A = A^{**} = R^* Q^* = R^*Q$.
$Q$ is unitary by construction, and $R^*$ is a lower triangular matrix with positive numbers on its diagonal.
