\section*{Chapter 7 - Operators on Inner Product Spaces}

\subsection*{Section 7A - Self-Adjoint and Normal Operators}

\subsubsection*{Exercise 1}

Suppose $n$ is a positive integer.
Define $T \in \mathcal{L}(\mathbb{F}^n)$ by $T(x_1, x_2, ..., x_n) = (0, x_1, ..., x_{n-1})$.
Find a formula for $T^*(x_1, x_2, ..., x_n)$.

\subsubsection*{Solution}

Take $T^*(y_1, y_2, ..., y_n) = (y_2, y_3, ..., y_n, 0)$, then
\begin{equation*}
    \begin{split}
        \langle T(x_1, x_2, ..., x_n), (y_1, y_2, ..., y_n) \rangle
            &= \langle (0, x_1, x_2, ..., x_{n-1}), (y_1, y_2, ..., y_n) \rangle \\
            &= x_1 y_2 + x_2 y_3 + ... + x_{n-1} y_n \\
            &= \langle (x_1, x_2, ..., x_n), (y_2, y_3, ..., y_{n-1}, 0) \rangle \\
            &= \langle (x_1, x_2, ..., x_n), T^*(y_1, y_2, ..., y_n) \rangle.
    \end{split}
\end{equation*}


\subsubsection*{Exercise 2}

Suppose $T \in \mathcal{L}(V, W)$.
Prove that the following are equivalent
\begin{enumerate}
\item $T = 0$,
\item $T^* = 0$,
\item $T^* T = 0$,
\item $T T^* = 0$.
\end{enumerate}

\subsubsection*{Solution}

Note that $\langle Tv, w\rangle = \langle v, T^*w \rangle$, for all $v, w$.
In particular $\langle Tv, Tv \rangle = \langle v, T^*Tv \rangle = \langle T^*T v, v \rangle$ and $\langle T^*w, T^*w\rangle = \langle T T^* w, w \rangle$ for all $v \in V$ and $w \in W$.
If $T = 0$, then $T^*T = 0$ and $TT^* = 0$.
Conversely if $T^*T = 0$ or $TT^* = 0$, then, using the first equation, $\langle Tv, Tv \rangle = 0$, hence $Tv = 0$ for all $v \in V$.
Therefore, $T = 0$.
If $T^* = 0$, then $T^*T = 0$ and $TT^* = 0$.
Conversely if $T^*T = 0$ or $TT^* = 0$, then, using the second equation, $\langle T^*v, T^*v \rangle = 0$, hence $T^*v = 0$ for all $v \in V$.
Therefore, $T^* = 0$.


\subsubsection*{Exercise 3}

Suppose $T \in \mathcal{L}(V)$ and $\lambda \in \mathbb{F}$.
Prove that $\lambda$ is an eigenvalue of $T$ if and only if $\overline{\lambda}$ is an eigenvalue of $T^*$.


\subsubsection*{Solution}

Note that from the previous exercise $T - \lambda I = 0$ if and only if $T^* - \overline{\lambda} I = (T - \lambda I)^* = 0$.
Which gives the result.


\subsubsection*{Exercise 4}

Suppose $T \in \mathcal{L}(V)$ and $U$ a subspace of $V$.
Show that $U$ is invariant under $T$ if and only if $U^{\perp}$ is invariant under $T^*$.

\subsubsection*{Solution}

\begin{itemize}
    \item[$\rightarrow)$] Let $v \in U^{\perp}$, so for all $u \in U$ we have $\langle u, v \rangle = 0$.
        We have, for all $v$, $\langle u, T^*v\rangle = \langle Tu, v\rangle = 0$, because $Tu \in U$, so $T^*u \in U^{\perp}$.
    \item[$\leftarrow)$] Let $u \in U$.
        For all $v \in U^{\perp}$, we have $\langle Tu, v \rangle = \langle u, T^*v \rangle = 0$, because $T^*v \in U^{\perp}$.
        Therefore $Tu \in (U^{\perp})^{\perp} = U$.
\end{itemize}


\subsubsection*{Exercise 5}

Suppose $T \in \mathcal{L}(V, W)$.
Suppose $e_1, e_2, ..., e_n$ is an orthonormal basis of $V$ and $f_1, f_2, ..., f_m$ is an orthonormal basis of $W$.
Prove that
\begin{equation*}
    ||Te_1||^2 + ... + ||Te_n||^2 = ||T^*f_1||^2 + ... + ||T^*f_m||^2.
\end{equation*}

\subsubsection*{Solution}

Because $\{e_i\}$ and $\{f_j\}$ are orthonormal basis we can write
\begin{equation*}
    Te_i = \langle Te_i, f_1 \rangle f_1 + ... + \langle Te_i, f_m \rangle f_m = \sum_{j=1}^m \langle Te_i, f_j \rangle f_j,
\end{equation*}
and
\begin{equation*}
    T^*f_j = \langle T^*f_j, e_1 \rangle e_1 + ... + \langle T^*f_j, e_n \rangle = \sum_{i=1}^n \langle T^*f_j, e_i \rangle e_i.
\end{equation*}
We have
\begin{equation*}
    \begin{split}
        ||Te_1||^2 + ... + ||Te_n||^2
            &= \sum_{i=1}^n \langle Te_i, Te_i \rangle \\
            &= \sum_{i=1}^n \langle \sum_{j=1}^m \langle Te_i, f_j \rangle f_j, Te_i \rangle \\
            &= \sum_{i=1}^n \sum_{j=1}^m \langle Te_i, f_j \rangle \langle f_j, Te_i \rangle \\
            &= \sum_{j=1}^m \sum_{i=1}^n \langle e_i, T^*f_j \rangle \langle T^*f_j, e_i \rangle \\
            &= \sum_{j=1}^m \sum_{i=1}^n \langle T^*f_j, e_i \rangle \langle e_i, T^*f_j \rangle \\
            &= \sum_{j=1}^m \langle \sum_{i=1}^n \langle T^*f_j, e_i \rangle e_i, T^*f_j \rangle \\
            &= \sum_{j=1}^m \langle T^*f_j, T^*f_j \rangle
            = ||T^*f_1||^2 + ... + ||T^*f_m||^2.
    \end{split}
\end{equation*}


\subsubsection*{Exercise 6}

Suppose $T \in \mathcal{L}(V, W)$.
Prove that
\begin{itemize}
\item[(a)] $T$ is injective if and only if $T^*$ is surjective.
\item[(b)] $T$ is surjective if and only if $T$ is injective.
\end{itemize}

\subsubsection*{Solution}

Follows from 7.6.
$T$ is injective if and only if $\nnull(T) = \{0\} = \range(T^*)^{\perp}$ if and only if $\range(T^*) = V$.
$T$ is surjective if and only if $\range(T) = V = \nnull(T^*)^{\perp}$ if and only if $\nnull(T^*) = \{0\}$.


\subsubsection*{Exercise 7}

Prove that if $T \in \mathcal{L}(V, W)$, then
\begin{itemize}
\item[(a)] $\dim(\nnull(T^*)) = \dim(\nnull(T)) + \dim(W) - \dim(V)$.
\item[(b)] $\dim(\range(T^*)) = \dim(\range(T))$.
\end{itemize}

\subsubsection*{Solution}

By 7.6 we have $\nnull(T^*) = \range(T)^{\perp}$, so, using 6.51, $\dim(\nnull(T^*)) = \dim(\range(T)^{\perp}) = \dim(W) - \dim(\range(T))$.
The fundamental theorem of linear maps, 3.21, gives $\dim(\range(T)) = \dim(V) - \dim(\nnull(T))$.
We get (a) by combining the previous results
\begin{equation*}
    \begin{split}
        \dim(\nnull(T^*)) &= \dim(\range(T)^{\perp}) \\
            &= \dim(W) - \dim(\range(T))
            = \dim(\nnull(T)) + \dim(W) - \dim(V).
    \end{split}
\end{equation*}
For (b) we have something similar.
We have
\begin{equation*}
    \begin{split}
        \dim(\range(T^*)) &= \dim(\nnull(T)^{\perp}) \\
            &= \dim(V) - \dim(\nnull(T)) \\
            &= \dim(V) - \dim(V) + \dim(\range(T))
            = \dim(\range(T)).
    \end{split}
\end{equation*}


\subsubsection*{Exercise 8}

Suppose $A$ is an $m$-by-$n$ matrix with entries in $\mathbb{F}$.
Use Exercise 7A.b to prove that the row rank of $A$ equals the column rank of $A$.

\subsubsection*{Solution}

Let $T \in \mathcal{L}(V, W)$ such that $\mathcal{M}(T) = A$.
We have
\begin{equation*}
    \text{column rank } A
        = \dim(\range(T))
        = \dim(\range(T^*))
        = \text{column rank } A^*
        = \text{row rank } A.
\end{equation*}
Exercise 7A.b is used in the second equality, theorem 7.9 is used in the last equality.


\subsubsection*{Exercise 9}

Prove that the product of two self-adjoint operators on $V$ is self-adjoint if and only if the two operators commute.

\subsubsection*{Solution}

Suppose $(ST)^* = ST$, then $TS = (TS)^{**} = (S^*T^*)^* = (ST)^* = ST$.
Conversely, if $ST = TS$, then $(ST)^* = T^*S^* = TS = ST$.


\subsubsection*{Exercise 10}

Suppose $\mathbb{F} = \mathbb{C}$ and $T \in \mathcal{L}(V)$.
Prove that $T$ is self-adjoint if and only if $\langle Tv, v \rangle = \langle T^*v, v \rangle$, for all $v \in V$.

\subsubsection*{Solution}

If $T$ is self-adjoint, then $\langle Tv, v \rangle = \langle T^*v, v \rangle$, for all $v \in V$.
Conversely, suppose $\langle Tv, v \rangle = \langle T^*v, v \rangle$, for all $v \in V$.
Take $S = T^* - T$.
Note that $\langle Sv, v \rangle = \langle Tv, v \rangle - \langle T^*v, v\rangle = 0$.
So, by 7.13, $S = 0$, hence $T = T^*$.


\subsubsection*{Exercise 11}

Define an operator $S: \mathbb{F}^2 \to \mathbb{F}^2: (x, y) \mapsto (-y, x)$.
\begin{itemize}
\item[(a)] Find a formula for $S^*$.
\item[(b)] Show that $S$ is normal but not self-adjoint.
\item[(c)] Find all eigenvalues of $S$.
\end{itemize}

\subsubsection*{Solution}
The formula for $S^*$ is $S^*(x, y) = (y, -x)$.
Note that $SS^*(x, y) = (x, y)$ and $S^*S(x, y) = (x, y)$, so $S^*S = I = SS^*$, hence $S$ is normal but not self-adjoint.
To find all the eigenvalues of $S$ solve the equation $S(x, y) = (-y, x) = \lambda(x, y)$.
Hence $\lambda x = -y$ and $\lambda y = x$.
So $x = \lambda y = -\lambda^2 x$, hence $\lambda^2 = 1$ or $\lambda = \pm i$ if $\mathbb{F} = \mathbb{C}$.
For $\mathbb{F} = \mathbb{R}$ there are no eigenvalues of $S$.


\subsubsection*{Exercise 12}

An operator $B \in \mathcal{L}(V)$ is called skew if $B^* = -B$.
Suppose that $T \in \mathcal{L}(V)$.
Prove that $T$ is normal if and only if there exists commuting operators $A$ and $B$ such that $A$ is self-adjoint, $B$ is a skew operator, and $T = A + B$.

\subsubsection*{Solution}

If $T = A + B$, then
\begin{equation*}
    TT^* = (A + B)(A^* - B)
        = AA^* - AB + BA^* - B^2
        = A^2 - B^2,
\end{equation*}
and
\begin{equation*}
    T^*T = (A^* - B)(A + B)
        = A^*A + A^*B - BA - B^2
        = A^2 - B^2.
\end{equation*}
We see that $T$ is normal.
Conversely, suppose $T$ is normal.
Take $A = \frac{1}{2}(T + T^*)$ and $B = \frac{1}{2}(T - T^*)$.
Clearly, we have $A$ is self-adjoint, $B$ is skew, and $T = A + B$.
We check that $A$ and $B$ commute.
\begin{equation*}
    AB = \frac{1}{4}(T + T^*)*(T - T^*)
        = \frac{1}{4}(T^2 + T^*T - TT^* - (T^*)^2)
        = \frac{1}{4}(T^2 - (T^*)^2),
\end{equation*}
and
\begin{equation*}
    BA = \frac{1}{4}(T - T^*)(T + T^*)
        = \frac{1}{4}(T^2 + TT^* - T^*T - (T^*)^2)
        = \frac{1}{4}(T^2 - (T^*)^2).
\end{equation*}
So $AB = BA$.
Which yield the result we have to show.


\subsubsection*{Exercise 13}

Suppose $\mathbb{F} = \mathbb{R}$.
Define $\mathcal{A} \in \mathcal{L}(\mathcal{L}(V))$ by $\mathcal{A}T = T^*$ for all $T \in \mathcal{L}(V)$.
\begin{itemize}
    \item[(a)] Find all eigenvalues of $\mathcal{A}$.
    \item[(b)] Find the minimal polynomial of $\mathcal{A}$.
\end{itemize}

\subsubsection*{Solution}

\begin{itemize}
    \item[(a)] We must have $\mathcal{A}(T) = T^* = \lambda T$.
        Taking the adjoint on both sides, $T = (T^*)^* = \overline{\lambda} T^* = |\lambda|^2 T$.
        As $\mathbb{F} = \mathbb{R}$, we must have $\lambda = \pm 1$ as eigenvalues.
    \item[(b)] Note $\mathcal{A}^2(T) = \mathcal{A}(T^*) = (T^*)^* = T$, so the minimal polynomial is a multiple of $p(x) = x^2 - 1$.
        From (a) we know that $\mathcal{A}$ has two eigenvalues, so $p(x)$ must be the minimal polynomial of $\mathcal{A}$.
\end{itemize}


\subsubsection*{Exercise 14}

Define an inner product on $\mathcal{P}_2(\mathbb{R})$ by $\langle p, q \rangle = \int_0^1 p(x) q(x) dx$.
Define an operator $T \in \mathcal{L}(\mathcal{P}_2(\mathbb{R}))$ by $T(ax^2 + bx + c) = bx$.
\begin{itemize}
    \item[(a)] Show that with this inner product, the operator $T$ is not self-adjoint.
    \item[(b)] The matrix of $T$ with respoect to the basis $1, x, x^2$ is
        \begin{equation*}
            \begin{pmatrix}
                0 & 0 & 0 \\
                0 & 1 & 0 \\
                0 & 0 & 0
            \end{pmatrix}
        \end{equation*}
        This matrix equals its conjugate transpose, even though $T$ is not self-adjoint.
        Explain why this is not a contradiction.
\end{itemize}

\subsubsection*{Solution}

\begin{itemize}
    \item[(a)] Take $p(x) = a_1 x^2 + b_1 x + c_1$ and $q(x) = a_2 x^2 + b_2 x + c_2$.
        If $T$ is self-adjoint, we should have $\langle Tp, q \rangle = \langle p, T^*q \rangle = \langle p, Tq \rangle$.
        We calculate
        \begin{equation*}
            \begin{split}
                \langle Tp, q \rangle
                    &= \int_0^1 Tp(x) q(x) dx
                    = \frac{1}{4} b_1 a_2 + \frac{1}{3} b_1 b_2 + \frac{1}{2} b_1 c_2, \\
                \langle p, Tq \rangle
                    &= \int_0^1 p(x) Tq(x) dx
                    = \frac{1}{4} a_1 b_2 + \frac{1}{3} b_1 b_2 + \frac{1}{2} c_1 b_2.
            \end{split}
        \end{equation*}
        So, in general, $\langle Tp, q \rangle \neq \langle p, Tq \rangle$.
    \item[(b)] For Theorem 7.9 to hold the basis in which the matrix is expressed needs to be orthonormal.
        The basis $\{1, x, x^2\}$ is not orthonormal.
\end{itemize}


\subsubsection*{Exercise 15}

Suppose $T \in \mathcal{L}(V)$ is invertible. Prove that
\begin{itemize}
\item[(a)] $T$ is self adjoint if and only if $T^{-1}$ is self-adjoint.
\item[(b)] $T$ is normal if and only if $T^{-1}$ is normal.
\end{itemize}

\subsubsection*{Solution}

We have $T = T^*$ if and only if $T^{-1} = (T^*)^{-1} = (T^{-1})^*$, by 7.5.f, which gives (a) immediately.
For (b) note that, it $T^{-1}$ is normal, $TT^* = ((T^*)^{-1}T^{-1})^{-1} = (T^{-1}(T^*)^{-1})^{-1} = T^*T$.
Conversely, substitute $T \leftarrow T^{-1}$ to get that if $T$ is normal than $T^{-1}$ is normal.


\subsubsection*{Exercise 16}

Suppose $\mathbb{F} = \mathbb{R}$.
\begin{itemize}
\item[(a)] Show that the set of self-adjoint operators on $V$ is a subspace of $\mathcal{L}(V)$.
\item[(b)] What is the dimension of the subspace of $\mathcal{L}(V)$ in (a)?
\end{itemize}

\subsubsection*{Solution}

Let $U = \{ T \in \mathcal{L}(V) : T^* = T \}$.
Let $S, T \in U$ and $\mu, \lambda \in \mathcal{F}$.
We have $(\mu S + \lambda T)^* = \mu S^* + \lambda T^* = \mu S + \lambda T$, so $\mu S + \lambda T \in U$.
Clearly $0 \in U$, so $U$ is a subspace of $\mathcal{L}(V)$.
A basis for $U$ is given by $\{e_{ij} + e_{ji}\}_{i \geq j}$.
Therefore, the dimension of $U$ is $\frac{1}{2}n(n+1)$.


\subsubsection*{Exercise 17}

Suppose $\mathbb{F} = \mathbb{C}$.
Show that the set of self-adjoint operators on $V$ is not a subspace of $\mathcal{L}(V)$.

\subsubsection*{Solution}

Note that $(i S)^* = \overline{i} S^* = -i S \neq i S$ if $S$ is a non-zero self-adjoint operator.


\subsubsection*{Exercise 18}

Suppose $\dim(V) \geq 2$.
Show that the set of normal operators on $V$ is not a subspace of $\mathcal{L}(V)$.

\subsubsection*{Solution}

TODO


\subsubsection*{Exercise 19}

Suppose $T \in \mathcal{L}(V)$ and $||T^*v|| \leq ||Tv||$ for every $v \in V$.
Prove that $T$ is normal.

\subsubsection*{Solution}

If $v \in \nnull(T)$ then $||T^*v|| \leq ||Tv|| = 0$, so $||T^*v|| = 0$, hence $\nnull(T^*) \subseteq \nnull(T)$.
Since $V$ is finite dimensional, using 6.49, $V = \range(T) \oplus (\range(T))^{\perp}$.
We have
\begin{equation*}
    V = \range(T) \oplus \range(T)^{\perp}
        = \range(T) \oplus \nnull(T^*)
        \subseteq \range(T) \oplus \nnull(T)
        \subseteq V
\end{equation*}
Hence, $\nnull(T^*) = \nnull(T)$.
From 7.21 it follows that $T$ is normal.


\subsubsection*{Exercise 20}

Suppose $P \in \mathcal{L}(V)$ is such that $P^2 = P$.
Prove that the following are equivalent: (a) $P$ is self-adjoint. (b) $P$ is normal. (c) There is a subspace $U$ of $V$ such that $P = P_U$.

\subsubsection*{Solution}

TODO


\subsubsection*{Exercise 21}

Suppose $D: \mathcal{P}_8(\mathbb{R}) \to \mathcal{P}_8(\mathbb{R})$ is the differentiation operator defined by $Dp = p'$.
Prove that there does not exist an inner product on $\mathcal{P}_8(\mathbb{R})$ that makes $D$ a normal operator.

\subsubsection*{Solution}

Note that $\range(T) \oplus \nnull(T) = \mathcal{P}_7(\mathbb{R}) \oplus \mathbb{R} \neq \mathcal{P}_8(\mathbb{R})$.
So $D$ can never be normal.


\subsubsection*{Exercise 22}

Give an example of an operator $T \in \mathbb{R}^3$ such that $T$ is normal but not self-adjoint.

\subsubsection*{Solution}

Extend example 7.19 to $\mathbb{R}^3$.
For example $T(x, y, z) = (2x - 2y, 3x + 2x, z)$.


\subsubsection*{Exercise 23}

Suppose $T$ is a normal operator on $V$.
Suppose also that $v, w \in V$ satisfy the equations $||v|| = ||w|| = 2$, $Tv = 3v$, and $Tw = 4w$.
Show that $||T(v + w)|| = 10$.

\subsubsection*{Solution}

Note that $v$ and $w$ are eigenvectors of $T$.
By 7.22, all eigenvectors with different eigenvalues are orthogonal, so $\langle v, w \rangle = 0$.
Therefore, we have $||T(v + w)||^2 = ||Tv||^2 + ||Tw||^2 = 3^2 ||v||^2 + 3^2 ||w||^2 = 100$.
So, $||T(v + w)|| = \sqrt{100} = 10$.


\subsubsection*{Exercise 24}

Suppose $T \in \mathcal{V}$ and $a_0 + a_1 x + ... + a_n x^n$ is the minimal polynomial of $T$.
Prove that the minimal polynomial of $T^*$ is $\overline{a_0} + \overline{a_1} x + ... + \overline{a_n} x^n$.

\subsubsection*{Solution 24}

By 5.27, the minimal polynomial of $T$ has the form $(x - \lambda_1)(x - \lambda_2)...(x - \lambda_n)$, where $\lambda_1, \lambda_2, ..., \lambda_n$ are the eigenvalues of $T$.
By exercise 7A.3, $\lambda_i$ is an eigenvalue of $T$ if and only if $\overline{\lambda_i}$ is an eigenvalue of $T^*$.
So, the minimal polynomial of $T^*$ is $(x - \overline{\lambda_1})(x - \overline{\lambda_2})...(x - \overline{\lambda_n})$.
Expanding the product we see that
\begin{equation*}
    \prod_{i = 1}^n (x - \overline{\lambda_i})
        = \overline{a_0} + \overline{a_1}x + ... + \overline{a_n} x^n.
\end{equation*}


\subsubsection*{Exercise 7A.25}

Suppose $T \in \mathcal{L}(V)$.
Prove that $T$ is diagonal if and only if $T^*$ is diagonal.

\subsubsection*{Solution}

From the previous exercise we know that $\prod_{i=1}^n (z - \lambda_i)$ is the minimal polynomial of $T$ if and only if $\prod_{i=1}^n (z - \overline{\lambda_i})$ is the minimal polynomial of $T^*$.
From 5.62 it follows that $T$ is diagonal if and only if $T^*$ is diagonal.


\subsubsection*{Exercise 7A.26}

Fix $u, v \in V$.
Define $T \in \mathcal{L}(V)$ by $Tv = \langle u, v \rangle x$ for every $v \in V$.
\begin{itemize}
    \item[(a)] Prove that if $V$ is a real vector space, then $T$ is self-adjoint if and only if the list $u, x$ is linearly independent.
    \item[(b)] Prove that $T$ is normal if and only if the list $u, x$ is linearly dependent.
\end{itemize}

\subsubsection*{Solution}

Note that
\begin{equation*}
    \langle v_1, T^* v_2 \rangle
        = \langle Tv_1, v_2 \rangle
        = \langle v_1, u \rangle \langle x, v_2 \rangle
        = \langle v_1, \overline{\langle x, v_2 \rangle} u \rangle,
\end{equation*}
so, $T^*v = \overline{\langle x, v\rangle} u = \langle v, x \rangle u$.

\begin{itemize}
    \item[(a)] $\rightarrow$, Suppose $T^* = T$.
        Then $\langle v, u \rangle x = \langle v, x \rangle u$ for all $v \in V$, so $x$ and $u$ are linear dependent as they are a scalar difference of each other.
        $\leftarrow$, Suppose $u$ and $x$ are linear dependent, i.e., $u = \lambda x$ for some $\lambda \in \mathbb{R}$ ($V$ is a real vector space).
        We have
        \begin{equation*}
            T^*v = \langle v, x \rangle u
                = \lambda \langle v, x \rangle x
                = \langle v, u \rangle x
                = Tv.
        \end{equation*}
    \item[(b)] $\rightarrow$, Suppose $T$ is normal.
        \begin{equation*}
            \langle x, v \rangle \langle u, u \rangle x
                = \langle v, x \rangle Tu
                = TT^* v
                = T^*T v
                = \langle v, u \rangle Tx
                = \langle v, u \rangle \langle x, x \rangle u.
        \end{equation*}
        So $x$ and $u$ are linear dependent as they are a scalar difference of each other.
        $\leftarrow$, Suppose $u = \lambda x$, then
        \begin{equation*}
            TT^*v
                = \langle x, v \rangle \langle u, u \rangle x
                = \langle x, v \rangle \langle x, x \rangle |\lambda|^2 x
                = \langle x, \lambda v \rangle \langle x, x \rangle \lambda x
                = \langle x, u \rangle \langle x, x \rangle u
                = T^*Tv,
        \end{equation*}
        for all $v \in V$.
\end{itemize}
